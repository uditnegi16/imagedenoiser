{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uditnegi16/imagedenoiser/blob/main/imagedenolise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ED5Eo10etj8"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dY4LIiLY4nl"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "# List all image paths\n",
        "TRAIN_NOISY_DIR = '/content/drive/MyDrive/imagedenoise/imagedenoise/BSDS300/images/train/noisy'\n",
        "TRAIN_CLEAN_DIR= '/content/drive/MyDrive/imagedenoise/imagedenoise/BSDS300/images/train/clean'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJzF5kl7ZA8_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the dimensions of the noisy and clean images\n",
        "for images in train_noisy_dataset.skip(40).take(1):\n",
        "    noisy_image = images[0]\n",
        "    print(\"Noisy image dimensions:\", noisy_image.shape)\n",
        "\n",
        "for images in train_clean_dataset.take(1):\n",
        "    clean_image = images[0]\n",
        "    print(\"Clean image dimensions:\", clean_image.shape)"
      ],
      "metadata": {
        "id": "iwVV5pbTsImm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rrr5SgVZFrw"
      },
      "outputs": [],
      "source": [
        "rescale_layer = tf.keras.layers.Rescaling(scale=1./255)\n",
        "# Combine the noisy and clean datasets\n",
        "train_dataset = tf.data.Dataset.zip((train_noisy_dataset, train_clean_dataset))\n",
        "# Apply the normalization function to the combined dataset\n",
        "# # Apply the rescaling layer to the combined dataset\n",
        "train_dataset_scaled = train_dataset.map(lambda x, y: (rescale_layer(x), rescale_layer(y)))\n",
        "# train_dataset_scaled = train_dataset.map(lambda noisy, clean: (rescale_layer(noisy), rescale_layer(clean)))/"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iV3x0kbEBl0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_scaled = train_dataset.map(lambda x, y: (tf.image.per_image_standardization(x), tf.image.per_image_standardization(y)))"
      ],
      "metadata": {
        "id": "mDLcIhbc8kz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print image values before rescaling\n",
        "for noisy, clean in train_dataset.take(1):\n",
        "    print(\"Before rescaling:\")\n",
        "    print(\"Noisy image values:\", noisy[0, 0, :5])  # print the first 5 pixel values of the first row of the noisy image\n",
        "    print(\"Clean image values:\", clean[0, 0, :5])  # print the first 5 pixel values of the first row of the clean image\n",
        "\n",
        "# Apply rescaling\n",
        "train_dataset_scaled = train_dataset.map(lambda x, y: (rescale_layer(x), rescale_layer(y)))\n",
        "\n",
        "# Print image values after rescaling\n",
        "for noisy, clean in train_dataset_scaled.take(1):\n",
        "    print(\"After rescaling:\")\n",
        "    print(\"Noisy image values:\", noisy[0, 0, :5])  # print the first 5 pixel values of the first row of the rescaled noisy image\n",
        "    print(\"Clean image values:\", clean[0, 0, :5])  # print the first 5 pixel values of the first row of the rescaled clean image"
      ],
      "metadata": {
        "id": "7-SIwxtB7wV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a for loop to print the shapes of the clean and noisy images\n",
        "for clean_image, noisy_image in train_dataset_scaled.take(1):\n",
        "    print(f\"Clean image shape: {clean_image.shape}, Noisy image shape: {noisy_image.shape}\")"
      ],
      "metadata": {
        "id": "vOXgIZtJ-Hb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# PSNR metric\n",
        "def psnr_loss(y_true, y_pred):\n",
        "    max_pixel_value = 255.0\n",
        "    return tf.image.psnr(y_true, y_pred, max_pixel_value)\n",
        "\n",
        "# Define the input shape\n",
        "input_shape = (448, 384, 3)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Encoder\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
        "    layers.MaxPooling2D((2, 2), padding='same'),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D((2, 2), padding='same'),\n",
        "\n",
        "    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D((2, 2), padding='same'),\n",
        "\n",
        "    # Decoder\n",
        "    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    layers.UpSampling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    layers.UpSampling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    layers.UpSampling2D((2, 2)),\n",
        "\n",
        "    # Output Layer\n",
        "    layers.Conv2D(3, (3, 3), activation='linear', padding='same')\n",
        "])\n",
        "\n",
        "# Compilation\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-4, weight_decay=1e-5),\n",
        "    loss='mean_squared_error',\n",
        "    metrics=[psnr_loss]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "DQx8nohkmdXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyKmmn2PZTFQ"
      },
      "outputs": [],
      "source": [
        "model.fit(\n",
        "   train_dataset_scaled,\n",
        "    epochs=30,\n",
        "    verbose=1\n",
        "    # validation_data=validation_dataset_scaled\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 2: Specify the path where you want to save the model\n",
        "model_save_path = '/content/drive/MyDrive/imagedenoise/denoising_model.keras'\n",
        "\n",
        "# Step 3: Save the trained model\n",
        "model.save(model_save_path)\n",
        "\n",
        "print(f\"Model saved to {model_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-8mHpNh8mB2",
        "outputId": "25b73ab6-caae-4158-d965-fc1b96424414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/MyDrive/imagedenoise/denoising_model.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stOkHHrQZW5R"
      },
      "outputs": [],
      "source": [
        "TEST_NOISY_DIR = '/content/drive/MyDrive/imagedenoise/imagedenoise/BSDS300/images/test/noisy'\n",
        "TEST_CLEAN_DIR = '/content/drive/MyDrive/imagedenoise/imagedenoise/BSDS300/images/test/clean'\n",
        "\n",
        "# Create the test noisy and clean datasets\n",
        "test_noisy_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    TEST_NOISY_DIR,\n",
        "    image_size=(448, 384),  # Resize images to 448x384\n",
        "    batch_size=3,\n",
        "    label_mode=None\n",
        ")\n",
        "\n",
        "test_clean_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    TEST_CLEAN_DIR,\n",
        "    image_size=(448, 384),  # Resize images to 448x384\n",
        "    batch_size=3,\n",
        "    label_mode=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABwt-RxnZmu7"
      },
      "outputs": [],
      "source": [
        "rescale_layer = tf.keras.layers.Rescaling(scale=1./255)\n",
        "# Combine the noisy and clean datasets\n",
        "test_dataset = tf.data.Dataset.zip((test_noisy_dataset, test_clean_dataset))\n",
        "\n",
        "# Apply the rescaling layer to the combined dataset\n",
        "test_dataset_scaled = test_dataset.map(lambda x, y: (tf.image.per_image_standardization(x), tf.image.per_image_standardization(y)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29MuSrC3Zwj8"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_psnr = model.evaluate(test_dataset_scaled, verbose=1)\n",
        "\n",
        "print(\"Test loss:\", test_loss)\n",
        "print(\"Test PSNR:\", test_psnr)\n",
        "\n",
        "# Generate predictions on the test dataset\n",
        "test_predictions = model.predict(test_dataset_scaled)\n",
        "# 3s - 306ms/step - loss: 0.1958 - psnr_loss: 61.0361\n",
        "# Test loss: 0.19577130675315857\n",
        "# Test PSNR: 61.03607940673828\n",
        "# # 9/9 ━━━━━━━━━━━━━━━━━━━━ 2s 135ms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from skimage.io import imsave\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the trained CNN denoising model\n",
        "# model = keras.models.load_model('/content/drive/MyDrive/imagedenoise/denoising_model.h5')\n",
        "\n",
        "# Load the PNG image from Google Drive\n",
        "image_path = '/content/drive/MyDrive/imagedenoise/15004.jpg'\n",
        "image_string = tf.io.read_file(image_path)\n",
        "img_noisy = tf.image.decode_png(image_string, channels=3)\n",
        "\n",
        "# Resize the image to (448, 384) as in the training dataset\n",
        "img_noisy = tf.image.resize(img_noisy, (448, 384))\n",
        "\n",
        "# Apply the same rescaling used during training\n",
        "img_noisy = tf.cast(img_noisy, tf.float32) / 255.0  # Normalize to [0, 1]\n",
        "\n",
        "# Add a batch dimension (necessary for model prediction)\n",
        "img_noisy = tf.expand_dims(img_noisy, axis=0)\n",
        "\n",
        "# Pass the noisy image to the denoising model\n",
        "denoised_img = model.predict(img_noisy)\n",
        "\n",
        "# Convert the denoised image back to the original range [0, 255]\n",
        "denoised_img = denoised_img[0] * 255.0  # Remove batch dimension and rescale\n",
        "denoised_img = tf.clip_by_value(denoised_img, 0, 255)  # Clip values to valid range\n",
        "denoised_img = denoised_img.numpy().astype(np.uint8)  # Convert to uint8 for saving and displaying\n",
        "\n",
        "# Save the denoised image\n",
        "imsave('denoised_image.png', denoised_img)\n",
        "\n",
        "# Display the denoised image\n",
        "plt.imshow(denoised_img)\n",
        "plt.axis('off')  # Hide the axes for cleaner display\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "47sYAyiN24Za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from skimage.io import imsave\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the trained CNN denoising model/\n",
        "# model = keras.models.load_model('/content/drive/MyDrive/imagedenoise/denoising_model.h5')\n",
        "\n",
        "# Load the PNG image from Google Drive\n",
        "image_path = '/content/drive/MyDrive/imagedenoise/gaussimage.png'\n",
        "image_string = tf.io.read_file(image_path)\n",
        "img_noisy = tf.image.decode_png(image_string, channels=3)\n",
        "\n",
        "# Step 1: Display the loaded image before any preprocessing\n",
        "plt.imshow(img_noisy.numpy())\n",
        "plt.title(\"Original Loaded Image\")\n",
        "plt.show()\n",
        "\n",
        "# Resize the image to (448, 384) as in the training dataset\n",
        "img_noisy = tf.image.resize(img_noisy, (448, 384))\n",
        "\n",
        "# Step 2: Display the resized image\n",
        "plt.imshow(img_noisy.numpy().astype(np.uint8))\n",
        "plt.title(\"Resized Image (448x384)\")\n",
        "plt.show()\n",
        "\n",
        "# Apply the same rescaling used during training\n",
        "img_noisy = tf.cast(img_noisy, tf.float32) / 255.0  # Normalize to [0, 1]\n",
        "\n",
        "# Step 3: Check if normalization is working as expected\n",
        "print(\"Noisy image max value (after normalization):\", tf.reduce_max(img_noisy).numpy())\n",
        "print(\"Noisy image min value (after normalization):\", tf.reduce_min(img_noisy).numpy())\n",
        "\n",
        "# Add a batch dimension (necessary for model prediction)\n",
        "img_noisy = tf.expand_dims(img_noisy, axis=0)\n",
        "\n",
        "# Pass the noisy image to the denoising model\n",
        "denoised_img = model.predict(img_noisy)\n",
        "\n",
        "# Convert the denoised image back to the original range [0, 255]\n",
        "denoised_img = denoised_img[0] * 255.0  # Remove batch dimension and rescale\n",
        "denoised_img = tf.clip_by_value(denoised_img, 0, 255)  # Clip values to valid range\n",
        "denoised_img = denoised_img.numpy().astype(np.uint8)  # Convert to uint8 for saving and displaying\n",
        "\n",
        "# Step 4: Display the denoised image after model prediction\n",
        "plt.imshow(denoised_img)\n",
        "plt.title(\"Denoised Image\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Save the denoised image\n",
        "imsave('denoised_image.png', denoised_img)\n"
      ],
      "metadata": {
        "id": "R7yjfjHT7cf5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Wcl4cfsvVD4pZZtCt1Ek0naYQ1xo0WaD",
      "authorship_tag": "ABX9TyMXjFnZzkdvbht+BXfUWvkE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}